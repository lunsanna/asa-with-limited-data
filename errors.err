WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   0%|          | 0/24 [00:00<?, ? examples/s]Map:   4%|▍         | 1/24 [00:00<00:03,  7.29 examples/s]Map:   4%|▍         | 1/24 [00:00<00:02,  7.82 examples/s]Map:   4%|▍         | 1/24 [00:00<00:02,  7.83 examples/s]Map:  21%|██        | 5/24 [00:00<00:00, 47.91 examples/s]Map:  29%|██▉       | 7/24 [00:00<00:00, 34.52 examples/s]Map:  33%|███▎      | 8/24 [00:00<00:00, 34.18 examples/s]Map:  33%|███▎      | 8/24 [00:00<00:00, 35.55 examples/s]Map:  46%|████▌     | 11/24 [00:00<00:00, 42.09 examples/s]Map:  50%|█████     | 12/24 [00:00<00:00, 36.57 examples/s]Map:  58%|█████▊    | 14/24 [00:00<00:00, 39.77 examples/s]Map:  58%|█████▊    | 14/24 [00:00<00:00, 38.85 examples/s]Map:  71%|███████   | 17/24 [00:00<00:00, 46.14 examples/s]Map:  75%|███████▌  | 18/24 [00:00<00:00, 41.96 examples/s]Map:  88%|████████▊ | 21/24 [00:00<00:00, 47.26 examples/s]Map:  88%|████████▊ | 21/24 [00:00<00:00, 46.64 examples/s]Map: 100%|██████████| 24/24 [00:00<00:00, 32.82 examples/s]                                                           Map: 100%|██████████| 24/24 [00:00<00:00, 31.43 examples/s]                                                                                                                                                                                 Map:   0%|          | 0/6 [00:00<?, ? examples/s]Map:   0%|          | 0/6 [00:00<?, ? examples/s]Map:   0%|          | 0/6 [00:00<?, ? examples/s]Map:   0%|          | 0/6 [00:00<?, ? examples/s]Map:  83%|████████▎ | 5/6 [00:00<00:00, 42.64 examples/s]Map:  83%|████████▎ | 5/6 [00:00<00:00, 41.74 examples/s]Map:  83%|████████▎ | 5/6 [00:00<00:00, 42.10 examples/s]Map:  83%|████████▎ | 5/6 [00:00<00:00, 42.24 examples/s]                                                                                                                                                                                                                                    Map (num_proc=6):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=6):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=6):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=6):   0%|          | 0/24 [00:00<?, ? examples/s]Map (num_proc=6):   4%|▍         | 1/24 [00:00<00:12,  1.89 examples/s]Map (num_proc=6):   4%|▍         | 1/24 [00:00<00:12,  1.82 examples/s]Map (num_proc=6):   4%|▍         | 1/24 [00:00<00:13,  1.73 examples/s]Map (num_proc=6):  12%|█▎        | 3/24 [00:00<00:03,  5.48 examples/s]Map (num_proc=6):  17%|█▋        | 4/24 [00:00<00:02,  7.31 examples/s]Map (num_proc=6):   8%|▊         | 2/24 [00:00<00:06,  3.16 examples/s]Map (num_proc=6):   4%|▍         | 1/24 [00:00<00:16,  1.41 examples/s]Map (num_proc=6):  21%|██        | 5/24 [00:00<00:03,  5.99 examples/s]Map (num_proc=6):  21%|██        | 5/24 [00:00<00:02,  6.73 examples/s]Map (num_proc=6):  21%|██        | 5/24 [00:00<00:03,  6.02 examples/s]Map (num_proc=6):  25%|██▌       | 6/24 [00:01<00:03,  5.54 examples/s]Map (num_proc=6):  42%|████▏     | 10/24 [00:01<00:01,  8.40 examples/s]Map (num_proc=6):  25%|██▌       | 6/24 [00:01<00:04,  3.72 examples/s]Map (num_proc=6):  25%|██▌       | 6/24 [00:01<00:05,  3.45 examples/s]Map (num_proc=6):  25%|██▌       | 6/24 [00:01<00:05,  3.16 examples/s]Map (num_proc=6):  50%|█████     | 12/24 [00:02<00:02,  4.64 examples/s]Map (num_proc=6):  50%|█████     | 12/24 [00:02<00:02,  5.71 examples/s]Map (num_proc=6):  46%|████▌     | 11/24 [00:02<00:02,  4.84 examples/s]Map (num_proc=6):  42%|████▏     | 10/24 [00:02<00:03,  4.14 examples/s]Map (num_proc=6):  62%|██████▎   | 15/24 [00:02<00:01,  6.35 examples/s]Map (num_proc=6):  67%|██████▋   | 16/24 [00:02<00:01,  5.86 examples/s]Map (num_proc=6):  71%|███████   | 17/24 [00:02<00:00,  7.37 examples/s]Map (num_proc=6):  71%|███████   | 17/24 [00:02<00:00,  7.62 examples/s]Map (num_proc=6):  88%|████████▊ | 21/24 [00:02<00:00,  9.62 examples/s]Map (num_proc=6):  88%|████████▊ | 21/24 [00:02<00:00, 10.91 examples/s]                                                                                                                                                                                                                                                                                                Map (num_proc=6):   0%|          | 0/6 [00:00<?, ? examples/s]Map (num_proc=6):   0%|          | 0/6 [00:00<?, ? examples/s]Map (num_proc=6):   0%|          | 0/6 [00:00<?, ? examples/s]Map (num_proc=6):   0%|          | 0/6 [00:00<?, ? examples/s]Map (num_proc=6):  17%|█▋        | 1/6 [00:00<00:01,  3.63 examples/s]Map (num_proc=6):  17%|█▋        | 1/6 [00:00<00:01,  3.14 examples/s]Map (num_proc=6):  17%|█▋        | 1/6 [00:00<00:02,  2.50 examples/s]Map (num_proc=6):  17%|█▋        | 1/6 [00:00<00:02,  2.42 examples/s]Map (num_proc=6):  33%|███▎      | 2/6 [00:00<00:00,  4.35 examples/s]Map (num_proc=6):  33%|███▎      | 2/6 [00:00<00:00,  4.11 examples/s]Map (num_proc=6):  33%|███▎      | 2/6 [00:00<00:01,  3.83 examples/s]Map (num_proc=6):  50%|█████     | 3/6 [00:00<00:00,  5.22 examples/s]Map (num_proc=6):  33%|███▎      | 2/6 [00:00<00:01,  3.38 examples/s]Map (num_proc=6):  50%|█████     | 3/6 [00:00<00:00,  4.61 examples/s]Map (num_proc=6):  50%|█████     | 3/6 [00:00<00:00,  4.88 examples/s]Map (num_proc=6):  50%|█████     | 3/6 [00:00<00:00,  4.52 examples/s]Map (num_proc=6):  67%|██████▋   | 4/6 [00:00<00:00,  5.63 examples/s]Map (num_proc=6):  67%|██████▋   | 4/6 [00:00<00:00,  5.37 examples/s]Map (num_proc=6):  67%|██████▋   | 4/6 [00:00<00:00,  4.60 examples/s]Map (num_proc=6):  83%|████████▎ | 5/6 [00:00<00:00,  5.98 examples/s]Map (num_proc=6):  67%|██████▋   | 4/6 [00:00<00:00,  4.92 examples/s]Map (num_proc=6): 100%|██████████| 6/6 [00:01<00:00,  7.51 examples/s]Map (num_proc=6):  83%|████████▎ | 5/6 [00:01<00:00,  5.54 examples/s]Map (num_proc=6):  83%|████████▎ | 5/6 [00:01<00:00,  5.94 examples/s]                                                                                                                                                                                                                                                                                        /scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Traceback (most recent call last):
  File "/scratch/work/lunt1/wav2vec2-finetune/finetune.py", line 394, in <module>
    run_train(i, processor, model, train_dataset,
  File "/scratch/work/lunt1/wav2vec2-finetune/finetune.py", line 285, in run_train
    out = model(input_values=batch.input_values,
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
Traceback (most recent call last):
  File "/scratch/work/lunt1/wav2vec2-finetune/finetune.py", line 394, in <module>
    return forward_call(*args, **kwargs)
    run_train(i, processor, model, train_dataset,
  File "/scratch/work/lunt1/wav2vec2-finetune/finetune.py", line 285, in run_train
        out = model(input_values=batch.input_values, 
          ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
^^^^^    ^return forward_call(*args, **kwargs)^
^^ ^ ^ ^ ^ ^ ^     ^^^^^^^^^^^^^
^^  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/accelerate/utils/operations.py", line 553, in forward
^^^    ^return model_forward(*args, **kwargs)^
^^ ^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/accelerate/utils/operations.py", line 553, in forward
 ^^    ^return model_forward(*args, **kwargs)^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/accelerate/utils/operations.py", line 541, in __call__
^^^^    ^return convert_to_fp32(self.model_forward(*args, **kwargs))^
^^ ^ ^ ^ 
    File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/accelerate/utils/operations.py", line 541, in __call__
        return convert_to_fp32(self.model_forward(*args, **kwargs)) 
                                ^^^^^^^^^ ^ ^^^^^ ^ ^ ^ ^ ^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
^^^^^^    ^return func(*args, **kwargs)^
^^ ^ ^ ^ ^ ^^ 
    File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 14, in decorate_autocast
   ^    ^return func(*args, **kwargs)^
^^ ^ ^ ^ ^     ^ ^ ^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
^^    ^output = self._run_ddp_forward(*inputs, **kwargs)^
^^ ^ ^ ^ 
    File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
        output = self._run_ddp_forward(*inputs, **kwargs) 
   ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
^^^    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
^^^^^^^^ ^ ^ ^ ^^^^ ^ ^ ^ ^ 
  ^^^  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
^^^    ^return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]^
^^ ^ ^ ^ ^ ^ ^   ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
^^^    ^return forward_call(*args, **kwargs)

  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
        return forward_call(*args, **kwargs) 
           ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
^^    
outputs = self.wav2vec2(
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1684, in forward
       outputs = self.wav2vec2( 
                   ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^
^^  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
^^    ^return forward_call(*args, **kwargs)

  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
        return forward_call(*args, **kwargs) 
           ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1320, in forward
^^^    
encoder_outputs = self.encoder(
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1320, in forward
        encoder_outputs = self.encoder( 
                                  ^ ^ ^^^ ^ ^ ^^^^^^^^^^^^
^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)    
return forward_call(*args, **kwargs)
                     ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 887, in forward
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 887, in forward
        layer_outputs = layer(layer_outputs = layer(

                                        ^^^^^^^^^^^^

  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)    
return forward_call(*args, **kwargs)
                     ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 719, in forward
^
      File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 719, in forward
hidden_states, attn_weights, _ = self.attention(
    hidden_states, attn_weights, _ = self.attention( 
                                                                      ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
^^^    ^return forward_call(*args, **kwargs)^
^^ 
      File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
       return forward_call(*args, **kwargs) 
   ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 593, in forward
^
    attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 617, in forward

       attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training) 
                         ~~~ ~ ~ ~ ~~~~~~~~~~ ~ ~ ~^~^~^~^~^~^~^~^~^~^~^~~~~^~~~~~~~^~~~~~~~~~~^~^~^~^~~~^~^^^~~~~~~~~~~~~^~^~^~^
^^torch.cuda^.^OutOfMemoryError^: ^CUDA out of memory. Tried to allocate 198.00 MiB (GPU 0; 15.89 GiB total capacity; 14.65 GiB already allocated; 69.88 MiB free; 14.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 612.00 MiB (GPU 2; 15.89 GiB total capacity; 14.03 GiB already allocated; 401.88 MiB free; 14.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 31653 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 31655 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 31652) of binary: /scratch/work/lunt1/.conda_envs/w2v2/bin/python
Traceback (most recent call last):
  File "/scratch/work/lunt1/.conda_envs/w2v2/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.0.1', 'console_scripts', 'torchrun')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/work/lunt1/.conda_envs/w2v2/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
finetune.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-06-28_14:28:42
  host      : gpu26.int.triton.aalto.fi
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 31654)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-06-28_14:28:42
  host      : gpu26.int.triton.aalto.fi
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 31652)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
